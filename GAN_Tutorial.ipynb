{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXmnbN7oTJB0Zwme28gBC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinTheRainmaker/AI_PlayGround/blob/main/GAN_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE1ZX4bFeXHG"
      },
      "source": [
        "!pip install keras matplotlib tensorflow tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N89jx0z8dVOT"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import initializers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-2eKnJ4eVBh"
      },
      "source": [
        "# Keras 가 Tensorflow 를 벡엔드로 사용할 수 있도록 설정\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "# seed 설정\n",
        "np.random.seed(10)\n",
        "\n",
        "# 랜덤 노이즈 벡터 차원 설정\n",
        "random_dim = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rHhuAJ7eOOK"
      },
      "source": [
        "def load_minst_data():\n",
        "    # 데이터 로드\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # 데이터를 -1 ~ 1 사이 값으로 normalize\n",
        "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
        "\n",
        "    # x_train을 (60000, 28, 28) 에서 (60000, 784) 로 reshape\n",
        "    # 한 row 당 784 columns\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "    return (x_train, y_train, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyMfZIhqgPGe"
      },
      "source": [
        "# Adam Optimizer를 사용\n",
        "def get_optimizer():\n",
        "    return Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "# Generator 만들기\n",
        "def get_generator(optimizer):\n",
        "    generator = Sequential()\n",
        "    generator.add(Dense(256, input_dim=random_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(512))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(1024))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "\n",
        "    generator.add(Dense(784, activation='tanh'))\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return generator\n",
        "\n",
        "# Discriminator 만들기\n",
        "def get_discriminator(optimizer):\n",
        "    discriminator = Sequential()\n",
        "    discriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(512))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(256))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    discriminator.add(Dropout(0.3))\n",
        "\n",
        "    discriminator.add(Dense(1, activation='sigmoid'))\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFTKx0yXgTVY"
      },
      "source": [
        "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
        "    # Generator와 Discriminator를 동시에 학습시키고 싶을 때 => trainable = False\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    gan_input = Input(shape=(random_dim,))\n",
        "\n",
        "    # Generator의 결과는 이미지\n",
        "    x = generator(gan_input)\n",
        "\n",
        "    # Discriminator의 결과는 이미지가 진짜인지 가짜인지에 대한 확률\n",
        "    gan_output = discriminator(x)\n",
        "\n",
        "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4HKCid8gdkT"
      },
      "source": [
        "# 생성된 MNIST 이미지를 보여주는 함수\n",
        "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[examples, random_dim])\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/gan_images/gan_generated_image_epoch_%d.png' % epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqtyFMDcgguC"
      },
      "source": [
        "def train(epochs=1, batch_size=128):\n",
        "    # train 데이터와 test 데이터 load\n",
        "    x_train, y_train, x_test, y_test = load_minst_data()\n",
        "\n",
        "    # train 데이터를 128 사이즈의 batch 로 분할\n",
        "    batch_count = x_train.shape[0] // batch_size\n",
        "\n",
        "    # GAN 네트워크 형성\n",
        "    adam = get_optimizer()\n",
        "    generator = get_generator(adam)\n",
        "    discriminator = get_discriminator(adam)\n",
        "    gan = get_gan_network(discriminator, random_dim, generator, adam)\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "        print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            # 입력으로 사용할 random 노이즈와 이미지 load\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "\n",
        "            image_batch = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n",
        "\n",
        "            # MNIST 이미지 생성\n",
        "            generated_images = generator.predict(noise)\n",
        "            X = np.concatenate([image_batch, generated_images])\n",
        "\n",
        "            y_dis = np.zeros(2*batch_size)\n",
        "            y_dis[:batch_size] = 0.9\n",
        "\n",
        "            # Discriminator 학습\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X, y_dis)\n",
        "\n",
        "            # Generator 학습\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "            y_gen = np.ones(batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "        if e == 1 or e % 20 == 0:\n",
        "            plot_generated_images(e, generator)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train(400, 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SrfLY6mgyFY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}